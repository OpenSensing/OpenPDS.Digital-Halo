{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inouts = {'results': '/Users/mpio/Dropbox/Apps/openPDS.Digital-Halo', \n",
    "#inouts = {'results': u'/Users/mpio/Work/DTL/OpenPDS.Digital-Halo/openPDS-2/answer_module', \n",
    "        'dbs': ['/Users/mpio/Library/Application Support/openPDS/dataSources/Digital-Halo/Digital-Halo_domain.db',\n",
    "                  '/Users/mpio/Library/Application Support/openPDS/dataSources/Digital-Halo/Digital-Halo_tracker.db']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%writefile digital_halo.py\n",
    "import sys\n",
    "import json\n",
    "from os import path\n",
    "import sqlite3\n",
    "from ast import literal_eval\n",
    "import decimal\n",
    "from decimal import Decimal\n",
    "import operator\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#inouts              = json.loads(sys.argv[1])\n",
    "dbs                 = inouts.get('dbs')\n",
    "results_folder      = inouts.get('results')\n",
    "model_file_name     = 'scrapped_us.json'\n",
    "model_path          = path.join(results_folder, 'model', model_file_name)\n",
    "\n",
    "RES_PATH                 = path.join(results_folder, 'res_per_tracker.json')\n",
    "RES_DETAILS_PATH         = path.join(results_folder, 'res_per_tracker_details.json')\n",
    "RES_COMPANY_DETAILS_PATH = path.join(results_folder, 'res_per_company_details.json')\n",
    "TRACKER_COUNTS_PATH      = path.join(results_folder, 'tracker_counts.json')\n",
    "\n",
    "\n",
    "\n",
    "DEMOGROUPS = {\n",
    "    'age'      : ('18', '18-24', '25-34', '35-44', '45-54', '55-64', '65'),\n",
    "    'education': ('College', 'Grad_School', 'No_College'),\n",
    "    'gender'   : ('Female', 'Male'),\n",
    "    'income'   : ('0-50k', '50-100k', '100-150k', '150k'),\n",
    "    'kids'     : ('Has_Kids', 'No_Kids'),\n",
    "    'race_US'  : ('Caucasian', 'African_American', 'Asian' , 'Hispanic')\n",
    "}\n",
    "\n",
    "priors = {\n",
    "    'age'  : {\"25_34\": 0.173, \"18\": 0.181, \"55_64\": 0.102, \"65\": 0.052, \"18_24\": 0.127, \"45_54\": 0.175, \"35_44\": 0.193},\n",
    "    'edu'  : {'No_College': 0.447, 'College': 0.408, 'Grad_School': 0.145},\n",
    "    'kids' : {'Has_Kids': 0.507, 'No_Kids': 0.493},\n",
    "    'inc'  : {'0-50k': 0.512, '50-100k': 0.283, '100-150k': 0.118, '150k': 0.082},\n",
    "    'etn'  : {'Caucasian': 0.762, 'African_American': 0.095, 'Asian': 0.047 , 'Hispanic': 0.096}\n",
    "}\n",
    "\n",
    "\n",
    "## model functions\n",
    "\n",
    "def loadModel (model_file):\n",
    "    \n",
    "    with open(model_file,'r') as data_fh:\n",
    "        model_dic = json.load(data_fh)\n",
    "        \n",
    "    return model_dic\n",
    "\n",
    "##### count the scores\n",
    "def normalize_products(categories_group):\n",
    "    total = sum(categories_group.values())\n",
    "    if total: \n",
    "        for category, product in categories_group.iteritems():\n",
    "            categories_group[category] = [product, float(product/total)]\n",
    "\n",
    "def average_probability(categories_group):\n",
    "    '''takes categories group as input to keep consistent with normalize_products()'''\n",
    "    for category, sum_and_count in categories_group.iteritems():\n",
    "        try:\n",
    "            sum_of_probs, count = sum_and_count\n",
    "            categories_group[category] = sum_of_probs/count\n",
    "        except ValueError:   # missing data\n",
    "            categories_group[category] = 'NA'\n",
    "        \n",
    "        \n",
    "def count_score (data):\n",
    "    '''\n",
    "    ins: data - dictionary containing domain names as keys and number of visits as values\n",
    "    outs: results - dictionary with category_groups -> categories -> [product of probs, normalized 'probability'] \n",
    "    ''' \n",
    "    #initialize results dict\n",
    "    results = {}\n",
    "    for gr_name, cat_labels in DEMOGROUPS.iteritems():\n",
    "        results[gr_name] = {cat: [] for cat in cat_labels}\n",
    "    \n",
    "    # flag for any data in the demographic model for the given browsing history data\n",
    "    any_data_in_model = False\n",
    "    for domain, count in data.iteritems():\n",
    "        if domain not in model: \n",
    "            continue\n",
    "        else:\n",
    "            domain = model[domain]\n",
    "            any_data_in_model = True\n",
    "            \n",
    "        for cat_gr, cats in results.iteritems():\n",
    "\n",
    "            for cat in cats.keys():\n",
    "                \n",
    "                if cat in domain:\n",
    "                    \n",
    "                    vals = domain[cat]\n",
    "                    if cats[cat]:   # some data for the category already exists\n",
    "                        cats[cat][0] += vals[1] * count\n",
    "                        cats[cat][1] += count\n",
    "                        \n",
    "                    else:           # no data for the cat so initalize it \n",
    "                        cats[cat].append(vals[1] * count)\n",
    "                        cats[cat].append(count)\n",
    "    #normalize to percentage like values and convert Decimal to float\n",
    "    if any_data_in_model:\n",
    "        for group in results.values():\n",
    "            average_probability(group)\n",
    "            #for cat_name, vals in group.iteritems():\n",
    "            #   if type(vals) == list:\n",
    "            #        vals[0] = float(vals[0])\n",
    "            #    if type(vals) == Decimal:\n",
    "            #        group[cat_name] = float(vals)\n",
    "    else:\n",
    "        results = 'NA'\n",
    "    \n",
    "    return results\n",
    "\n",
    "## extract simple results\n",
    "\n",
    "def get_top_categories(detailed_results):\n",
    "    results = deepcopy(detailed_results)\n",
    "    for tracker_name, val in results.iteritems():\n",
    "        if val == 'NA':\n",
    "            results[tracker_name] = 'NA'\n",
    "        else:\n",
    "            cat_groups = val\n",
    "            for group_name, cats in cat_groups.iteritems():\n",
    "                \n",
    "                try:\n",
    "                    top_cat = max(cats.keys(), key= lambda cat_name: cats[cat_name][1])\n",
    "                    results[tracker_name][group_name] = (top_cat, cats[top_cat][1])\n",
    "                except TypeError:\n",
    "                    results[tracker_name][group_name] = 'NA'\n",
    "    \n",
    "    return results\n",
    "##### Functions for demographics per comapny                \n",
    "\n",
    "def count_scores_per_company():\n",
    "    \n",
    "    company_names_query = 'SELECT DISTINCT owner FROM tracker'\n",
    "    trackerdb_cur.execute(company_names_query)\n",
    "    \n",
    "    company_names = []\n",
    "    for company in trackerdb_cur.fetchall():\n",
    "        company_names.append(company[0])   # fetchall returns an array of tuples\n",
    "    \n",
    "    for company in company_names:\n",
    "        all_company_domains = set()\n",
    "        all_company_trackers_query = 'SELECT name, domains FROM tracker where owner=\"{0}\"'.format( company )\n",
    "        trackerdb_cur.execute(all_company_trackers_query)\n",
    "        for tracker, domains in trackerdb_cur.fetchall():\n",
    "            all_company_domains = all_company_domains.union(literal_eval(domains))\n",
    "        \n",
    "        ###  TODO  :    SQLite can only take up to 999 ? which means 999 tracked domains, should work for now but fix it\n",
    "        select_tracked = 'SELECT name, total FROM domain WHERE name in ({seq})'.format(\n",
    "            seq=','.join(['?']*len(all_company_domains)))\n",
    "        domaindb_cur.execute(select_tracked, list(all_company_domains))\n",
    "        tracked_history = {}\n",
    "        for name, total_count in domaindb_cur.fetchall():\n",
    "            tracked_history[name] = total_count\n",
    "        \n",
    "        ## calculate scores\n",
    "        if tracked_history:\n",
    "            results_per_company[company] = count_score(tracked_history)\n",
    "        else:\n",
    "            results_per_company[company] = 'Not Tracked'\n",
    "           \n",
    "    \n",
    "##### Function for tracker counts \n",
    "\n",
    "def get_tracking_company_details (company_name):\n",
    "    details = {\n",
    "        'name'    : company_name,\n",
    "        'count'   : 0,\n",
    "        'children': []\n",
    "    }\n",
    "\n",
    "    all_company_trackers_query = 'SELECT name, timesSeen FROM tracker where owner=\"{0}\"'.format( company_name )\n",
    "    trackerdb_cur.execute(all_company_trackers_query)\n",
    "    \n",
    "    for tracker, tracker_count in trackerdb_cur.fetchall():\n",
    "        details['count'] += tracker_count\n",
    "        details['children'].append({'name':tracker, 'count':tracker_count})\n",
    "\n",
    "    return details\n",
    "\n",
    "def get_all_tracking_companies_details ():\n",
    "    all_details = []\n",
    "\n",
    "    company_names_query = 'SELECT DISTINCT owner FROM tracker'\n",
    "    trackerdb_cur.execute(company_names_query)\n",
    "    \n",
    "    for company_name in trackerdb_cur.fetchall():\n",
    "        company_name = company_name[0]   #fetchall returns a tuple for every record\n",
    "\n",
    "        all_details.append(get_tracking_company_details(company_name))\n",
    "\n",
    "    all_details.sort(key = lambda x: x['count'], reverse = True)\n",
    "    for company in all_details:\n",
    "        company['children'].sort(key = lambda x: x['count'], reverse = True)\n",
    "\n",
    "    return all_details\n",
    "\n",
    "                    \n",
    "######### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## open dbs\n",
    "for dbpath in dbs:\n",
    "    if path.split(dbpath)[1] == 'Digital-Halo_domain.db':\n",
    "        domaindb     = sqlite3.connect(dbpath)\n",
    "    elif path.split(dbpath)[1] == 'Digital-Halo_tracker.db':\n",
    "        trackerdb    = sqlite3.connect(dbpath)\n",
    "## check if correct DB file names have been passed by checking if dbs connections have been crated\n",
    "## errors while trying to open are going to raise exceptions in the loop above \n",
    "try: \n",
    "    domaindb\n",
    "except NameError:\n",
    "    raise ValueError('\"Digital-Halo_domain.db\" path missing ')\n",
    "try: \n",
    "    trackerdb\n",
    "except NameError:\n",
    "    raise ValueError('\"Digital-Halo_domain.db\" path missing ')\n",
    "\n",
    "## get cursors\n",
    "domaindb_cur  = domaindb.cursor()    \n",
    "trackerdb_cur = trackerdb.cursor()    \n",
    "\n",
    "#### model work\n",
    "model  = loadModel(model_path)\n",
    "\n",
    "\n",
    "##################################### CALCULATE RESULTS\n",
    "## calculate total results\n",
    "results             = {}\n",
    "results_per_company = {}\n",
    "\n",
    "## pull all visited pay-level domains with visit counts and store it in a dictionary\n",
    "total_browsing_history = {}\n",
    "select_whole_history = 'SELECT name, total FROM domain'\n",
    "domaindb_cur.execute(select_whole_history)\n",
    "for name, total in domaindb_cur.fetchall():\n",
    "    total_browsing_history[name] = total\n",
    "\n",
    "# calculate demographic stats from full browsing history\n",
    "results['total']     = count_score(total_browsing_history) \n",
    "\n",
    "## pull all trackers with pay level domains tracked by each of the trackers\n",
    "select_trackers_query = 'SELECT name, domains FROM tracker'\n",
    "trackerdb_cur.execute(select_trackers_query)\n",
    "\n",
    "for tracker, domains in trackerdb_cur.fetchall():\n",
    "    '''for each tracker fetch all visits to tracked domains'''\n",
    "    domains = literal_eval(domains)\n",
    "    \n",
    "    select_tracked = 'SELECT name, total FROM domain WHERE name in ({seq})'.format(\n",
    "        seq=','.join(['?']*len(domains)))\n",
    "    domaindb_cur.execute(select_tracked, domains)\n",
    "    tracked_history = {}\n",
    "    for name, total_count in domaindb_cur.fetchall():\n",
    "        tracked_history[name] = total_count\n",
    "    # done loading relveant (tracked) history\n",
    "    \n",
    "    ## calculate scores\n",
    "    if tracked_history:\n",
    "        results[tracker] = count_score(tracked_history)\n",
    "    else:\n",
    "        results[tracker] = 'Not Tracked'\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# extract top category for each group\n",
    "simple_results = get_top_categories(results)\n",
    "\n",
    "## count scores per tracking company\n",
    "count_scores_per_company()\n",
    "\n",
    "## get number of occurances of each tracker and aggregate them over owning companies\n",
    "tracker_and_company_counts = get_all_tracking_companies_details()\n",
    "\n",
    "################################################  Save results\n",
    "\n",
    "with open (RES_PATH, 'w') as res_file:\n",
    "    json.dump(simple_results, res_file)\n",
    "with open (RES_DETAILS_PATH, 'w') as res_det_file:\n",
    "    json.dump(results, res_det_file)\n",
    "with open (RES_COMPANY_DETAILS_PATH, 'w') as res_cmp_file:\n",
    "    json.dump(results_per_company, res_cmp_file)\n",
    "with open (TRACKER_COUNTS_PATH, 'w') as tr_counts_file:\n",
    "    json.dump(tracker_and_company_counts, tr_counts_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
